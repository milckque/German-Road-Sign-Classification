{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "1e527e36-032c-4967-bbdc-a7eacbb19d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "train_data = pd.read_csv(\"train/train_metadata.csv\")\n",
    "train_data_additional = pd.read_csv(\"train/Features/additional_features.csv\")\n",
    "train_data_color_histogram = pd.read_csv(\"train/Features/color_histogram.csv\")\n",
    "train_data_hog_pca = pd.read_csv(\"train/Features/hog_pca.csv\")\n",
    "\n",
    "train_features = pd.merge(train_data_color_histogram, train_data_hog_pca, on='image_path')\n",
    "train_features = pd.merge(train_features, train_data_additional, on='image_path')\n",
    "train_features = pd.merge(train_features, train_data[['image_path', 'ClassId']], on='image_path')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# checking for class imbalance\n",
    "\n",
    "class_counts = train_features['ClassId'].value_counts()\n",
    "# print(class_counts)\n",
    "\n",
    "plt.figure(figsize=(15, 6))\n",
    "class_counts.plot(kind='bar')\n",
    "plt.title('Class Distribution')\n",
    "plt.xlabel('Class ID')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Processsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image enhancement and normalization\n",
    "import cv2\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# loads and resizes image to 1000 x 1000 pixels\n",
    "def load_image(path, data_type):\n",
    "    path = os.path.join(data_type, path)  \n",
    "    img = cv2.imread(path)\n",
    "    img = cv2.resize(img, (1000, 1000))\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    return img\n",
    "\n",
    "# # Reading the input image\n",
    "# def erode_dilate(img):\n",
    "    \n",
    "#     # Taking a matrix of size 5 as the kernel\n",
    "#     kernel = np.ones((5, 5), np.uint8)\n",
    "\n",
    "#     # The first parameter is the original image,\n",
    "#     # kernel is the matrix with which image is\n",
    "#     # convolved and third parameter is the number\n",
    "#     # of iterations, which will determine how much\n",
    "#     # you want to erode/dilate a given image.\n",
    "#     img_erosion = cv2.erode(img, kernel, iterations=1)\n",
    "#     img_dilation = cv2.dilate(img, kernel, iterations=1)\n",
    "\n",
    "#     cv2.imshow('Input', img)\n",
    "#     cv2.imshow('Erosion', img_erosion)\n",
    "#     cv2.imshow('Dilation', img_dilation)\n",
    "\n",
    "# erode_dilate(load_image('img_000001.jpg'))\n",
    "\n",
    "\n",
    "# not that necessary, images already very small n blurry, after scaling up theres barely any noise\n",
    "# def de_noise(img):\n",
    "#     dst = cv2.fastNlMeansDenoisingColored(img, None, 10, 10, 7, 15)\n",
    "#     return dst\n",
    "\n",
    "# https://www.geeksforgeeks.org/clahe-histogram-eqalization-opencv/\n",
    "def enhance_image(img):\n",
    "    # converting to LAB color space so we can up teh brightness without affecting colors\n",
    "    lab = cv2.cvtColor(img, cv2.COLOR_RGB2LAB)\n",
    "    \n",
    "    # applying CLAHE to only the brightness channel \n",
    "    clahe = cv2.createCLAHE(clipLimit=5)\n",
    "    lab[:,:,0] = clahe.apply(lab[:,:,0])\n",
    "    \n",
    "    enhanced = cv2.cvtColor(lab, cv2.COLOR_LAB2RGB) \n",
    "\n",
    "    return enhanced\n",
    "\n",
    "# modified circle detection function from \n",
    "# https://www.geeksforgeeks.org/circle-detection-using-opencv-python/\n",
    "def detect_circle(img):\n",
    "    # Convert to grayscale.\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "    # Blur using 3 * 3 kernel.\n",
    "    gray_blurred = cv2.blur(gray, (3, 3))\n",
    "\n",
    "    # Apply Hough transform on the blurred image\n",
    "    detected_circles = cv2.HoughCircles(gray_blurred, \n",
    "                   cv2.HOUGH_GRADIENT, 1, 20, param1 = 50,\n",
    "               param2 = 30, minRadius = 100, maxRadius = 500)\n",
    "\n",
    "    return 1 if detected_circles is not None else 0\n",
    "\n",
    "\n",
    "# # Demonstrate enhancement on a few images\n",
    "# # written by claude\n",
    "# sample_images = train_features['image_path'].values[15:20]\n",
    "# plt.figure(figsize=(20, 10))\n",
    "# for i, img_path in enumerate(sample_images):\n",
    "#     img = load_image(img_path)\n",
    "#     if img is not None:\n",
    "#         enhanced = enhance_image(img)\n",
    "#         circle = detect_circle(enhanced)\n",
    "#         print(circle)\n",
    "        \n",
    "#         plt.subplot(3, 5, i+1)\n",
    "#         plt.imshow(img)\n",
    "#         plt.title('Original')\n",
    "#         plt.axis('off')\n",
    "        \n",
    "#         plt.subplot(3, 5, i+6)\n",
    "#         plt.imshow(enhanced)\n",
    "#         plt.title('Enhanced')\n",
    "#         plt.axis('off')\n",
    "\n",
    "# plt.tight_layout()\n",
    "# # plt.show()\n",
    "\n",
    "\n",
    "# extracts color features from an image\n",
    "def extract_color_features(img):\n",
    "    features = []\n",
    "\n",
    "    # RGB stats\n",
    "    for i, channel in enumerate(['R', 'G', 'B']):\n",
    "        channel_data = img[:,:,i].flatten()\n",
    "        mean = np.mean(channel_data)\n",
    "        std = np.std(channel_data)\n",
    "        skew = (3 * (mean - np.median(channel_data))) / std if std > 0 else 0\n",
    "\n",
    "        # 10th and 90th percentiles for capturing color distribution without outlier influence\n",
    "        p10 = np.percentile(channel_data, 10)\n",
    "        p90 = np.percentile(channel_data, 90)\n",
    "        \n",
    "        features.extend([std, skew, p10, p90])\n",
    "    \n",
    "    # HSV stats \n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
    "    for i, channel in enumerate(['H', 'S', 'V']):\n",
    "        channel_data = hsv[:,:,i].flatten()\n",
    "        mean = np.mean(channel_data)\n",
    "        std = np.std(channel_data)\n",
    "        features.extend([mean, std])\n",
    "    \n",
    "    return features\n",
    "\n",
    "def process_all_images(metadata_df, data_type):\n",
    "    all_features = []\n",
    "    feature_names = ['image_path']\n",
    "    \n",
    "    rgb_features = ['std_r', 'skew_r', 'p10_r', 'p90_r', \n",
    "                   'std_g', 'skew_g', 'p10_g', 'p90_g',\n",
    "                   'std_b', 'skew_b', 'p10_b', 'p90_b']\n",
    "    \n",
    "    hsv_features = ['mean_h', 'std_h', 'mean_s', 'std_s', 'mean_v', 'std_v']\n",
    "    \n",
    "    feature_names.extend(rgb_features)\n",
    "    feature_names.extend(hsv_features)\n",
    "    \n",
    "    for idx, row in tqdm(metadata_df.iterrows(), total=len(metadata_df), desc=\"Processing images\"):\n",
    "        image_path = row['image_path']\n",
    "        img = load_image(image_path, data_type)\n",
    "        enhanced = enhance_image(img)\n",
    "        color_features = extract_color_features(enhanced)\n",
    "        features = [image_path] + color_features\n",
    "        all_features.append(features)\n",
    "            \n",
    "    features_df = pd.DataFrame(all_features, columns=feature_names)\n",
    "\n",
    "    features_df.to_csv('aaaaa.csv', index=False)\n",
    "    return features_df "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images: 100%|██████████| 5488/5488 [02:40<00:00, 34.13it/s]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "processed_image_features = process_all_images(train_data, 'train')\n",
    "train_features = pd.merge(processed_image_features, train_features, on='image_path')\n",
    "\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# feature_columns = [col for col in train_features.columns if col not in ['image_path', 'ClassId']]\n",
    "# train_features[feature_columns] = StandardScaler().fit_transform(train_features[feature_columns])\n",
    "\n",
    "X = train_features.drop(['image_path', 'ClassId'], axis=1)\n",
    "y = train_features['ClassId']\n",
    "X_train, X_eval, y_train, y_eval = train_test_split(X, y, test_size=0.2, random_state=30027, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running experiments with test set size: 0.01\n",
      "Average Test Accuracy over 100 runs: 0.5789 ± 0.0610\n",
      "Min: 0.4545, Max: 0.7273\n",
      "\n",
      "Running experiments with test set size: 0.1\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "dt = DecisionTreeClassifier(max_depth=10000)\n",
    "import numpy as np\n",
    "\n",
    "for test_size in [0.01, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]:\n",
    "    print('Running experiments with test set size: {}'.format(test_size))\n",
    "    accuracies = []\n",
    "    \n",
    "    for i in range(50):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=i)\n",
    "        \n",
    "        dt.fit(X_train, y_train)\n",
    "        dt_acc = accuracy_score(dt.predict(X_test), y_test)\n",
    "        accuracies.append(dt_acc)\n",
    "    \n",
    "    avg_accuracy = np.mean(accuracies)\n",
    "    std_accuracy = np.std(accuracies)\n",
    "    print('Average Test Accuracy over 100 runs: {:.4f} ± {:.4f}'.format(avg_accuracy, std_accuracy))\n",
    "    print('Min: {:.4f}, Max: {:.4f}'.format(np.min(accuracies), np.max(accuracies)))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.  hog_pca_0  :  0.3682\n",
      "2.  hog_pca_7  :  0.3309\n",
      "3.  hog_pca_3  : -0.3275\n",
      "4.  p10_b_x    :  0.3217\n",
      "5.  p10_b_y    :  0.3217\n",
      "6.  hog_pca_8  :  0.3137\n",
      "7.  hog_pca_2  : -0.2958\n",
      "8.  mean_s_x   :  0.2721\n",
      "9.  mean_s_y   :  0.2721\n",
      "10. p10_r_x    : -0.2707\n",
      "11. p10_r_y    : -0.2707\n",
      "12. std_s_x    :  0.2191\n",
      "13. std_s_y    :  0.2191\n",
      "14. std_h_x    : -0.1974\n",
      "15. std_h_y    : -0.1974\n",
      "16. p10_g_x    :  0.1705\n",
      "17. p10_g_y    :  0.1705\n",
      "18. hog_pca_12 : -0.1667\n",
      "19. mean_b     :  0.1468\n",
      "20. std_r_x    :  0.1275\n"
     ]
    }
   ],
   "source": [
    "# getting the top 20 features most correlated with class\n",
    "correlations = []\n",
    "for col in train_features.columns:\n",
    "    if col not in ['image_path', 'ClassId']:\n",
    "        corr = train_features[col].corr(train_features['ClassId'])\n",
    "        correlations.append((col, corr))\n",
    "\n",
    "top_correlations = sorted(correlations, key=lambda x: abs(x[1]), reverse=True)[:20]\n",
    "for num, (feature, corr) in enumerate(top_correlations):\n",
    "    print(f\"{str(num + 1) + '.':<3} {feature:<11}: {corr:7.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This will take a while. Be Patient!\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/lionelliu/Library/Mobile Documents/com~apple~CloudDocs/Uni/3rd Year/COMP30027 Machine Learning/Proj 2 -(/German-Road-Sign-Classification/ml assign 2/COMP30027_ass_2.ipynb Cell 9\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/lionelliu/Library/Mobile%20Documents/com~apple~CloudDocs/Uni/3rd%20Year/COMP30027%20Machine%20Learning/Proj%202%20-%28/German-Road-Sign-Classification/ml%20assign%202/COMP30027_ass_2.ipynb#X12sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m \u001b[39m# Use GridSearchCV to find the best max_iter value\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/lionelliu/Library/Mobile%20Documents/com~apple~CloudDocs/Uni/3rd%20Year/COMP30027%20Machine%20Learning/Proj%202%20-%28/German-Road-Sign-Classification/ml%20assign%202/COMP30027_ass_2.ipynb#X12sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m grid_search \u001b[39m=\u001b[39m GridSearchCV(lgr, param_grid, cv\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/lionelliu/Library/Mobile%20Documents/com~apple~CloudDocs/Uni/3rd%20Year/COMP30027%20Machine%20Learning/Proj%202%20-%28/German-Road-Sign-Classification/ml%20assign%202/COMP30027_ass_2.ipynb#X12sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m grid_search\u001b[39m.\u001b[39mfit(X_train, y_train)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/lionelliu/Library/Mobile%20Documents/com~apple~CloudDocs/Uni/3rd%20Year/COMP30027%20Machine%20Learning/Proj%202%20-%28/German-Road-Sign-Classification/ml%20assign%202/COMP30027_ass_2.ipynb#X12sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m \u001b[39m# Print the best parameters and accuracy score\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/lionelliu/Library/Mobile%20Documents/com~apple~CloudDocs/Uni/3rd%20Year/COMP30027%20Machine%20Learning/Proj%202%20-%28/German-Road-Sign-Classification/ml%20assign%202/COMP30027_ass_2.ipynb#X12sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mBest max_iter value:\u001b[39m\u001b[39m\"\u001b[39m, grid_search\u001b[39m.\u001b[39mbest_params_[\u001b[39m'\u001b[39m\u001b[39mmax_iter\u001b[39m\u001b[39m'\u001b[39m])\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1467\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[1;32m   1469\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m   1470\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1472\u001b[0m     )\n\u001b[1;32m   1473\u001b[0m ):\n\u001b[0;32m-> 1474\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/model_selection/_search.py:970\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m    964\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[1;32m    965\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    966\u001b[0m     )\n\u001b[1;32m    968\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[0;32m--> 970\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_run_search(evaluate_candidates)\n\u001b[1;32m    972\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    973\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    974\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1527\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1525\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1526\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1527\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparam_grid))\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/model_selection/_search.py:916\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    908\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    909\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[1;32m    910\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFitting \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m folds for each of \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m candidates,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    911\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m totalling \u001b[39m\u001b[39m{2}\u001b[39;00m\u001b[39m fits\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m    912\u001b[0m             n_splits, n_candidates, n_candidates \u001b[39m*\u001b[39m n_splits\n\u001b[1;32m    913\u001b[0m         )\n\u001b[1;32m    914\u001b[0m     )\n\u001b[0;32m--> 916\u001b[0m out \u001b[39m=\u001b[39m parallel(\n\u001b[1;32m    917\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m    918\u001b[0m         clone(base_estimator),\n\u001b[1;32m    919\u001b[0m         X,\n\u001b[1;32m    920\u001b[0m         y,\n\u001b[1;32m    921\u001b[0m         train\u001b[39m=\u001b[39mtrain,\n\u001b[1;32m    922\u001b[0m         test\u001b[39m=\u001b[39mtest,\n\u001b[1;32m    923\u001b[0m         parameters\u001b[39m=\u001b[39mparameters,\n\u001b[1;32m    924\u001b[0m         split_progress\u001b[39m=\u001b[39m(split_idx, n_splits),\n\u001b[1;32m    925\u001b[0m         candidate_progress\u001b[39m=\u001b[39m(cand_idx, n_candidates),\n\u001b[1;32m    926\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_and_score_kwargs,\n\u001b[1;32m    927\u001b[0m     )\n\u001b[1;32m    928\u001b[0m     \u001b[39mfor\u001b[39;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[39min\u001b[39;00m product(\n\u001b[1;32m    929\u001b[0m         \u001b[39menumerate\u001b[39m(candidate_params),\n\u001b[1;32m    930\u001b[0m         \u001b[39menumerate\u001b[39m(cv\u001b[39m.\u001b[39msplit(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mrouted_params\u001b[39m.\u001b[39msplitter\u001b[39m.\u001b[39msplit)),\n\u001b[1;32m    931\u001b[0m     )\n\u001b[1;32m    932\u001b[0m )\n\u001b[1;32m    934\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    935\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    936\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo fits were performed. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    937\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWas the CV iterator empty? \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    938\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWere there no candidates?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    939\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/parallel.py:67\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     62\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[1;32m     63\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[1;32m     64\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     65\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[1;32m     66\u001b[0m )\n\u001b[0;32m---> 67\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/joblib/parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1916\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1917\u001b[0m     \u001b[39mnext\u001b[39m(output)\n\u001b[0;32m-> 1918\u001b[0m     \u001b[39mreturn\u001b[39;00m output \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreturn_generator \u001b[39melse\u001b[39;00m \u001b[39mlist\u001b[39m(output)\n\u001b[1;32m   1920\u001b[0m \u001b[39m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1921\u001b[0m \u001b[39m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1922\u001b[0m \u001b[39m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1923\u001b[0m \u001b[39m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1924\u001b[0m \u001b[39m# callback.\u001b[39;00m\n\u001b[1;32m   1925\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/joblib/parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1845\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_dispatched_batches \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   1846\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_dispatched_tasks \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m-> 1847\u001b[0m res \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m   1848\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_completed_tasks \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   1849\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprint_progress()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/parallel.py:129\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    127\u001b[0m     config \u001b[39m=\u001b[39m {}\n\u001b[1;32m    128\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconfig):\n\u001b[0;32m--> 129\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:895\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, score_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    893\u001b[0m         estimator\u001b[39m.\u001b[39mfit(X_train, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[1;32m    894\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 895\u001b[0m         estimator\u001b[39m.\u001b[39mfit(X_train, y_train, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[1;32m    897\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[1;32m    898\u001b[0m     \u001b[39m# Note fit time as time until error\u001b[39;00m\n\u001b[1;32m    899\u001b[0m     fit_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1467\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[1;32m   1469\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m   1470\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1472\u001b[0m     )\n\u001b[1;32m   1473\u001b[0m ):\n\u001b[0;32m-> 1474\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1296\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1293\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1294\u001b[0m     n_threads \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m-> 1296\u001b[0m fold_coefs_ \u001b[39m=\u001b[39m Parallel(n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_jobs, verbose\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose, prefer\u001b[39m=\u001b[39mprefer)(\n\u001b[1;32m   1297\u001b[0m     path_func(\n\u001b[1;32m   1298\u001b[0m         X,\n\u001b[1;32m   1299\u001b[0m         y,\n\u001b[1;32m   1300\u001b[0m         pos_class\u001b[39m=\u001b[39mclass_,\n\u001b[1;32m   1301\u001b[0m         Cs\u001b[39m=\u001b[39m[C_],\n\u001b[1;32m   1302\u001b[0m         l1_ratio\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39ml1_ratio,\n\u001b[1;32m   1303\u001b[0m         fit_intercept\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit_intercept,\n\u001b[1;32m   1304\u001b[0m         tol\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtol,\n\u001b[1;32m   1305\u001b[0m         verbose\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose,\n\u001b[1;32m   1306\u001b[0m         solver\u001b[39m=\u001b[39msolver,\n\u001b[1;32m   1307\u001b[0m         multi_class\u001b[39m=\u001b[39mmulti_class,\n\u001b[1;32m   1308\u001b[0m         max_iter\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_iter,\n\u001b[1;32m   1309\u001b[0m         class_weight\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclass_weight,\n\u001b[1;32m   1310\u001b[0m         check_input\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m   1311\u001b[0m         random_state\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrandom_state,\n\u001b[1;32m   1312\u001b[0m         coef\u001b[39m=\u001b[39mwarm_start_coef_,\n\u001b[1;32m   1313\u001b[0m         penalty\u001b[39m=\u001b[39mpenalty,\n\u001b[1;32m   1314\u001b[0m         max_squared_sum\u001b[39m=\u001b[39mmax_squared_sum,\n\u001b[1;32m   1315\u001b[0m         sample_weight\u001b[39m=\u001b[39msample_weight,\n\u001b[1;32m   1316\u001b[0m         n_threads\u001b[39m=\u001b[39mn_threads,\n\u001b[1;32m   1317\u001b[0m     )\n\u001b[1;32m   1318\u001b[0m     \u001b[39mfor\u001b[39;00m class_, warm_start_coef_ \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(classes_, warm_start_coef)\n\u001b[1;32m   1319\u001b[0m )\n\u001b[1;32m   1321\u001b[0m fold_coefs_, _, n_iter_ \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mfold_coefs_)\n\u001b[1;32m   1322\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_iter_ \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray(n_iter_, dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mint32)[:, \u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/parallel.py:67\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     62\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[1;32m     63\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[1;32m     64\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     65\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[1;32m     66\u001b[0m )\n\u001b[0;32m---> 67\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/joblib/parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1916\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1917\u001b[0m     \u001b[39mnext\u001b[39m(output)\n\u001b[0;32m-> 1918\u001b[0m     \u001b[39mreturn\u001b[39;00m output \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreturn_generator \u001b[39melse\u001b[39;00m \u001b[39mlist\u001b[39m(output)\n\u001b[1;32m   1920\u001b[0m \u001b[39m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1921\u001b[0m \u001b[39m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1922\u001b[0m \u001b[39m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1923\u001b[0m \u001b[39m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1924\u001b[0m \u001b[39m# callback.\u001b[39;00m\n\u001b[1;32m   1925\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/joblib/parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1845\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_dispatched_batches \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   1846\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_dispatched_tasks \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m-> 1847\u001b[0m res \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m   1848\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_completed_tasks \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   1849\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprint_progress()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/parallel.py:129\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    127\u001b[0m     config \u001b[39m=\u001b[39m {}\n\u001b[1;32m    128\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconfig):\n\u001b[0;32m--> 129\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:455\u001b[0m, in \u001b[0;36m_logistic_regression_path\u001b[0;34m(X, y, pos_class, Cs, fit_intercept, max_iter, tol, verbose, solver, coef, class_weight, dual, penalty, intercept_scaling, multi_class, random_state, check_input, max_squared_sum, sample_weight, l1_ratio, n_threads)\u001b[0m\n\u001b[1;32m    451\u001b[0m l2_reg_strength \u001b[39m=\u001b[39m \u001b[39m1.0\u001b[39m \u001b[39m/\u001b[39m (C \u001b[39m*\u001b[39m sw_sum)\n\u001b[1;32m    452\u001b[0m iprint \u001b[39m=\u001b[39m [\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m50\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m100\u001b[39m, \u001b[39m101\u001b[39m][\n\u001b[1;32m    453\u001b[0m     np\u001b[39m.\u001b[39msearchsorted(np\u001b[39m.\u001b[39marray([\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m, \u001b[39m3\u001b[39m]), verbose)\n\u001b[1;32m    454\u001b[0m ]\n\u001b[0;32m--> 455\u001b[0m opt_res \u001b[39m=\u001b[39m optimize\u001b[39m.\u001b[39mminimize(\n\u001b[1;32m    456\u001b[0m     func,\n\u001b[1;32m    457\u001b[0m     w0,\n\u001b[1;32m    458\u001b[0m     method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mL-BFGS-B\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    459\u001b[0m     jac\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m    460\u001b[0m     args\u001b[39m=\u001b[39m(X, target, sample_weight, l2_reg_strength, n_threads),\n\u001b[1;32m    461\u001b[0m     options\u001b[39m=\u001b[39m{\n\u001b[1;32m    462\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mmaxiter\u001b[39m\u001b[39m\"\u001b[39m: max_iter,\n\u001b[1;32m    463\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mmaxls\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m50\u001b[39m,  \u001b[39m# default is 20\u001b[39;00m\n\u001b[1;32m    464\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39miprint\u001b[39m\u001b[39m\"\u001b[39m: iprint,\n\u001b[1;32m    465\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mgtol\u001b[39m\u001b[39m\"\u001b[39m: tol,\n\u001b[1;32m    466\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mftol\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m64\u001b[39m \u001b[39m*\u001b[39m np\u001b[39m.\u001b[39mfinfo(\u001b[39mfloat\u001b[39m)\u001b[39m.\u001b[39meps,\n\u001b[1;32m    467\u001b[0m     },\n\u001b[1;32m    468\u001b[0m )\n\u001b[1;32m    469\u001b[0m n_iter_i \u001b[39m=\u001b[39m _check_optimize_result(\n\u001b[1;32m    470\u001b[0m     solver,\n\u001b[1;32m    471\u001b[0m     opt_res,\n\u001b[1;32m    472\u001b[0m     max_iter,\n\u001b[1;32m    473\u001b[0m     extra_warning_msg\u001b[39m=\u001b[39m_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n\u001b[1;32m    474\u001b[0m )\n\u001b[1;32m    475\u001b[0m w0, loss \u001b[39m=\u001b[39m opt_res\u001b[39m.\u001b[39mx, opt_res\u001b[39m.\u001b[39mfun\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_minimize.py:713\u001b[0m, in \u001b[0;36mminimize\u001b[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[1;32m    710\u001b[0m     res \u001b[39m=\u001b[39m _minimize_newtoncg(fun, x0, args, jac, hess, hessp, callback,\n\u001b[1;32m    711\u001b[0m                              \u001b[39m*\u001b[39m\u001b[39m*\u001b[39moptions)\n\u001b[1;32m    712\u001b[0m \u001b[39melif\u001b[39;00m meth \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39ml-bfgs-b\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m--> 713\u001b[0m     res \u001b[39m=\u001b[39m _minimize_lbfgsb(fun, x0, args, jac, bounds,\n\u001b[1;32m    714\u001b[0m                            callback\u001b[39m=\u001b[39mcallback, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39moptions)\n\u001b[1;32m    715\u001b[0m \u001b[39melif\u001b[39;00m meth \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mtnc\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    716\u001b[0m     res \u001b[39m=\u001b[39m _minimize_tnc(fun, x0, args, jac, bounds, callback\u001b[39m=\u001b[39mcallback,\n\u001b[1;32m    717\u001b[0m                         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39moptions)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_lbfgsb_py.py:407\u001b[0m, in \u001b[0;36m_minimize_lbfgsb\u001b[0;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[1;32m    401\u001b[0m task_str \u001b[39m=\u001b[39m task\u001b[39m.\u001b[39mtobytes()\n\u001b[1;32m    402\u001b[0m \u001b[39mif\u001b[39;00m task_str\u001b[39m.\u001b[39mstartswith(\u001b[39mb\u001b[39m\u001b[39m'\u001b[39m\u001b[39mFG\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m    403\u001b[0m     \u001b[39m# The minimization routine wants f and g at the current x.\u001b[39;00m\n\u001b[1;32m    404\u001b[0m     \u001b[39m# Note that interruptions due to maxfun are postponed\u001b[39;00m\n\u001b[1;32m    405\u001b[0m     \u001b[39m# until the completion of the current minimization iteration.\u001b[39;00m\n\u001b[1;32m    406\u001b[0m     \u001b[39m# Overwrite f and g:\u001b[39;00m\n\u001b[0;32m--> 407\u001b[0m     f, g \u001b[39m=\u001b[39m func_and_grad(x)\n\u001b[1;32m    408\u001b[0m \u001b[39melif\u001b[39;00m task_str\u001b[39m.\u001b[39mstartswith(\u001b[39mb\u001b[39m\u001b[39m'\u001b[39m\u001b[39mNEW_X\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m    409\u001b[0m     \u001b[39m# new iteration\u001b[39;00m\n\u001b[1;32m    410\u001b[0m     n_iterations \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_differentiable_functions.py:296\u001b[0m, in \u001b[0;36mScalarFunction.fun_and_grad\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    294\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m np\u001b[39m.\u001b[39marray_equal(x, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mx):\n\u001b[1;32m    295\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_x_impl(x)\n\u001b[0;32m--> 296\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_fun()\n\u001b[1;32m    297\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_grad()\n\u001b[1;32m    298\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mf, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mg\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_differentiable_functions.py:262\u001b[0m, in \u001b[0;36mScalarFunction._update_fun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_update_fun\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    261\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mf_updated:\n\u001b[0;32m--> 262\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_fun_impl()\n\u001b[1;32m    263\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mf_updated \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_differentiable_functions.py:163\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.update_fun\u001b[0;34m()\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mupdate_fun\u001b[39m():\n\u001b[0;32m--> 163\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mf \u001b[39m=\u001b[39m fun_wrapped(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mx)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_differentiable_functions.py:145\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.fun_wrapped\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnfev \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    142\u001b[0m \u001b[39m# Send a copy because the user may overwrite it.\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \u001b[39m# Overwriting results in undefined behaviour because\u001b[39;00m\n\u001b[1;32m    144\u001b[0m \u001b[39m# fun(self.x) will change self.x, with the two no longer linked.\u001b[39;00m\n\u001b[0;32m--> 145\u001b[0m fx \u001b[39m=\u001b[39m fun(np\u001b[39m.\u001b[39mcopy(x), \u001b[39m*\u001b[39margs)\n\u001b[1;32m    146\u001b[0m \u001b[39m# Make sure the function returns a true scalar\u001b[39;00m\n\u001b[1;32m    147\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m np\u001b[39m.\u001b[39misscalar(fx):\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_optimize.py:79\u001b[0m, in \u001b[0;36mMemoizeJac.__call__\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, x, \u001b[39m*\u001b[39margs):\n\u001b[1;32m     78\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\" returns the function value \"\"\"\u001b[39;00m\n\u001b[0;32m---> 79\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compute_if_needed(x, \u001b[39m*\u001b[39margs)\n\u001b[1;32m     80\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_value\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_optimize.py:73\u001b[0m, in \u001b[0;36mMemoizeJac._compute_if_needed\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m np\u001b[39m.\u001b[39mall(x \u001b[39m==\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mx) \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_value \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mjac \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mx \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray(x)\u001b[39m.\u001b[39mcopy()\n\u001b[0;32m---> 73\u001b[0m     fg \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfun(x, \u001b[39m*\u001b[39margs)\n\u001b[1;32m     74\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mjac \u001b[39m=\u001b[39m fg[\u001b[39m1\u001b[39m]\n\u001b[1;32m     75\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_value \u001b[39m=\u001b[39m fg[\u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_linear_loss.py:302\u001b[0m, in \u001b[0;36mLinearModelLoss.loss_gradient\u001b[0;34m(self, coef, X, y, sample_weight, l2_reg_strength, n_threads, raw_prediction)\u001b[0m\n\u001b[1;32m    300\u001b[0m grad[:, :n_features] \u001b[39m=\u001b[39m grad_pointwise\u001b[39m.\u001b[39mT \u001b[39m@\u001b[39m X \u001b[39m+\u001b[39m l2_reg_strength \u001b[39m*\u001b[39m weights\n\u001b[1;32m    301\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit_intercept:\n\u001b[0;32m--> 302\u001b[0m     grad[:, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m] \u001b[39m=\u001b[39m grad_pointwise\u001b[39m.\u001b[39msum(axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[1;32m    303\u001b[0m \u001b[39mif\u001b[39;00m coef\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    304\u001b[0m     grad \u001b[39m=\u001b[39m grad\u001b[39m.\u001b[39mravel(order\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mF\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/numpy/core/_methods.py:47\u001b[0m, in \u001b[0;36m_sum\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_amin\u001b[39m(a, axis\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, out\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, keepdims\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m     44\u001b[0m           initial\u001b[39m=\u001b[39m_NoValue, where\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[1;32m     45\u001b[0m     \u001b[39mreturn\u001b[39;00m umr_minimum(a, axis, \u001b[39mNone\u001b[39;00m, out, keepdims, initial, where)\n\u001b[0;32m---> 47\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_sum\u001b[39m(a, axis\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, out\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, keepdims\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m     48\u001b[0m          initial\u001b[39m=\u001b[39m_NoValue, where\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[1;32m     49\u001b[0m     \u001b[39mreturn\u001b[39;00m umr_sum(a, axis, dtype, out, keepdims, initial, where)\n\u001b[1;32m     51\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_prod\u001b[39m(a, axis\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, out\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, keepdims\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m     52\u001b[0m           initial\u001b[39m=\u001b[39m_NoValue, where\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)\n",
    "\n",
    "# Define the parameter grid to search over\n",
    "# param_grid = {'max_iter': [100, 500, 1000, 5000, 10000]}\n",
    "\n",
    "# param_grid = {'max_iter': [10000, 15000, 20000]}\n",
    "# param_grid = {'max_iter': [7500, 10000, 12500]}\n",
    "# param_grid = {'max_iter': [9000, 10000, 11000]}\n",
    "param_grid = {'max_iter': [10500, 11000, 11500]}\n",
    "\n",
    "# param_grid = {'max_iter': [5000, 7500, 10000]}\n",
    "# param_grid = {'max_iter': [5000, 6250, 7500]}\n",
    "# param_grid = {'max_iter': [6000, 6250, 6500]}\n",
    "# param_grid = {'max_iter': [6200, 6250, 6300]}\n",
    "\n",
    "# Create a logistic regression classifier\n",
    "lgr = LogisticRegression()\n",
    "\n",
    "print(\"This will take a while. Be Patient!\")\n",
    "\n",
    "# Use GridSearchCV to find the best max_iter value\n",
    "grid_search = GridSearchCV(lgr, param_grid, cv=3)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters and accuracy score\n",
    "print(\"Best max_iter value:\", grid_search.best_params_['max_iter'])\n",
    "print(\"Accuracy:\", grid_search.score(X_eval, y_eval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/svm/_classes.py:31: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/svm/_classes.py:31: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/svm/_classes.py:31: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/svm/_classes.py:31: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/svm/_classes.py:31: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/svm/_classes.py:31: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/svm/_classes.py:31: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/svm/_classes.py:31: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/svm/_classes.py:31: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/svm/_classes.py:31: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naives Bayes ; Cross Validation Acc 0.23123362982463141\n",
      "1-R ; Cross Validation Acc 0.11024124818847805\n",
      "1-Nearest Neighbour ; Cross Validation Acc 0.6047754377567707\n",
      "5-Nearest Neighbour ; Cross Validation Acc 0.42930211532580803\n",
      "Decision Tree ; Cross Validation Acc 0.5599510722880353\n",
      "LinearSVC ; Cross Validation Acc 0.41266735803650967\n",
      "SVM with a cubic kernel ; Cross Validation Acc 0.057398322098573394\n",
      "SVM with an RBF kernel ; Cross Validation Acc 0.16381310411763925\n",
      "Logistic Regression ; Cross Validation Acc 0.8163296238682143\n",
      "Random Forest ; Cross Validation Acc 0.8187022190312844\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#try to change C to 1000 or 0.001\n",
    "C = 1.0  # SVM regularization parameter\n",
    "\n",
    "models = [GaussianNB(),\n",
    "        #   MultinomialNB(),\n",
    "          DecisionTreeClassifier(max_depth=1), #Cross Validation Acc 0.11024124818847805\n",
    "          KNeighborsClassifier(n_neighbors=1),\n",
    "          KNeighborsClassifier(n_neighbors=5),\n",
    "          DecisionTreeClassifier(max_depth=None),\n",
    "          svm.LinearSVC(C=C),\n",
    "          svm.SVC(kernel='rbf', gamma=0.7, C=C), #Cross Validation Acc 0.15761105128102856\n",
    "          svm.SVC(kernel='poly', degree=3, C=C), #Cross Validation Acc 0.13228730405647962\n",
    "          LogisticRegression(max_iter=11000),\n",
    "          RandomForestClassifier(n_estimators=100, random_state=30027)          ]\n",
    "\n",
    "titles = ['Naives Bayes',\n",
    "        #   'Multinomial Naives Bayes',\n",
    "          '1-R',\n",
    "          '1-Nearest Neighbour',\n",
    "          '5-Nearest Neighbour',\n",
    "          'Decision Tree',\n",
    "          'LinearSVC',\n",
    "          'SVM with a cubic kernel',\n",
    "          'SVM with an RBF kernel',\n",
    "          'Logistic Regression',\n",
    "          'Random Forest']\n",
    "\n",
    "# title_training_acc = {}\n",
    "# for title, model in zip(titles, models):\n",
    "#     model.fit(X_train, y_train)\n",
    "#     title_training_acc[title] = model.score(X_eval, y_eval)\n",
    "\n",
    "title_crossvalidation_acc = {}\n",
    "for title, model in zip(titles, models):\n",
    "    title_crossvalidation_acc[title] = np.mean(cross_val_score(model, X, y, cv=10))\n",
    "\n",
    "# for title in titles:\n",
    "#     print(title, ': Training Acc', title_training_acc[title], '; Cross Validation Acc', title_crossvalidation_acc[title])\n",
    "\n",
    "for title in titles:\n",
    "    print(title, '; Cross Validation Acc', title_crossvalidation_acc[title])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stacker Accuracy (Logistic Regression): 0.8305739514348786\n",
      "\n",
      "Stacker Accuracy (Decision Tree): 0.4768211920529801\n"
     ]
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "np.random.seed(30027)\n",
    "\n",
    "class StackingClassifier():\n",
    "\n",
    "    def __init__(self, classifiers, metaclassifier):\n",
    "        self.classifiers = classifiers\n",
    "        self.metaclassifier = metaclassifier\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        for clf in self.classifiers:\n",
    "            clf.fit(X, y)\n",
    "        X_meta = self._predict_base(X) #X_meta is the output (y_hat) of the base classifiers\n",
    "        self.metaclassifier.fit(X_meta, y) #output of the base classifiers is the input for the meta classifier\n",
    "    \n",
    "    def _predict_base(self, X):\n",
    "        yhats = []\n",
    "        for clf in self.classifiers:\n",
    "            yhat = clf.predict_proba(X)\n",
    "            yhats.append(yhat)\n",
    "        yhats = np.concatenate(yhats, axis=1)\n",
    "        assert yhats.shape[0] == X.shape[0] # check that the number of rows yhats matches the number of rows in the input data X\n",
    "        return yhats\n",
    "    \n",
    "    def predict(self, X):\n",
    "        X_meta = self._predict_base(X)     \n",
    "        yhat = self.metaclassifier.predict(X_meta)\n",
    "        return yhat\n",
    "    def score(self, X, y):\n",
    "        yhat = self.predict(X)\n",
    "        return accuracy_score(y, yhat)\n",
    "    \n",
    "\n",
    "# classifiers = [ KNeighborsClassifier(n_neighbors=1),\n",
    "#                 DecisionTreeClassifier(max_depth=None),\n",
    "#                 # svm.LinearSVC(C=C),\n",
    "#                 LogisticRegression(max_iter=6250),\n",
    "#                 RandomForestClassifier(n_estimators=100, random_state=30027)]\n",
    "# titles = ['1-Nearest Neighbour',\n",
    "#           'Decision Tree',\n",
    "#         #   'LinearSVC',\n",
    "#           'Logistic Regression',\n",
    "#           'Random Forest']\n",
    "    \n",
    "classifiers = [ LogisticRegression(max_iter=11000),\n",
    "                RandomForestClassifier(n_estimators=100, random_state=30027)]\n",
    "titles = ['Logistic Regression',\n",
    "          'Random Forest']\n",
    "\n",
    "meta_classifier_lr = LogisticRegression()\n",
    "stacker_lr = StackingClassifier(classifiers, meta_classifier_lr)\n",
    "\n",
    "meta_classifier_dt = DecisionTreeClassifier()\n",
    "stacker_dt = StackingClassifier(classifiers, meta_classifier_dt)\n",
    "\n",
    "stacker_lr.fit(X_train, y_train)\n",
    "print('\\nStacker Accuracy (Logistic Regression):', stacker_lr.score(X_eval, y_eval))\n",
    "\n",
    "stacker_dt.fit(X_train, y_train)\n",
    "print('\\nStacker Accuracy (Decision Tree):', stacker_dt.score(X_eval, y_eval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logreg: 0.7941501103752759\n",
      "Logreg Bagging Accuracy: 0.7163355408388521\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "logreg = LogisticRegression(max_iter=11000)\n",
    "bagging = BaggingClassifier(estimator=LogisticRegression(max_iter=11000), n_estimators=50,\\\n",
    "                              max_samples=0.5, max_features=0.5)\n",
    "logreg.fit(X_train,y_train)\n",
    "bagging.fit(X_train,y_train)\n",
    "\n",
    "print(\"Logreg:\",logreg.score(X_eval,y_eval))\n",
    "print(\"Logreg Bagging Accuracy:\",bagging.score(X_eval,y_eval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf: 0.7814569536423841\n",
      "bagging_rf Accuracy: 0.7179911699779249\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=30027)\n",
    "bagging_rf = BaggingClassifier(estimator=RandomForestClassifier(n_estimators=100, random_state=30027), n_estimators=50,\\\n",
    "                              max_samples=0.5, max_features=0.5)\n",
    "rf.fit(X_train,y_train)\n",
    "bagging_rf.fit(X_train,y_train)\n",
    "\n",
    "print(\"rf:\",rf.score(X_eval,y_eval))\n",
    "print(\"bagging_rf Accuracy:\",bagging_rf.score(X_eval,y_eval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(\"test/test_metadata.csv\")\n",
    "test_data_additional = pd.read_csv(\"test/Features/additional_features.csv\")\n",
    "test_data_color_histogram = pd.read_csv(\"test/Features/color_histogram.csv\")\n",
    "test_data_hog_pca = pd.read_csv(\"test/Features/hog_pca.csv\")\n",
    "\n",
    "test_features = pd.merge(test_data_color_histogram, test_data_hog_pca, on='image_path')\n",
    "test_features = pd.merge(test_features, test_data_additional, on='image_path')\n",
    "test_features = pd.merge(test_features, test_data[['image_path', 'ClassId']], on='image_path')\n",
    "\n",
    "processed_test_image_features = process_all_images(test_data, 'test')\n",
    "\n",
    "test_features = pd.merge(processed_test_image_features, test_features, on='image_path')\n",
    "\n",
    "# test_features[feature_columns] = StandardScaler().fit_transform(test_features[feature_columns])\n",
    "\n",
    "X_test = test_features.drop(['image_path', 'ClassId'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- mean_h\n- mean_s\n- mean_v\n- p10_b\n- p10_g\n- ...\nFeature names seen at fit time, yet now missing:\n- mean_h_x\n- mean_h_y\n- mean_s_x\n- mean_s_y\n- mean_v_x\n- ...\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/lionelliu/Library/Mobile Documents/com~apple~CloudDocs/Uni/3rd Year/COMP30027 Machine Learning/Proj 2 -(/German-Road-Sign-Classification/ml assign 2/COMP30027_ass_2.ipynb Cell 15\u001b[0m line \u001b[0;36m7\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/lionelliu/Library/Mobile%20Documents/com~apple~CloudDocs/Uni/3rd%20Year/COMP30027%20Machine%20Learning/Proj%202%20-%28/German-Road-Sign-Classification/ml%20assign%202/COMP30027_ass_2.ipynb#X20sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m rf \u001b[39m=\u001b[39m RandomForestClassifier(n_estimators\u001b[39m=\u001b[39m\u001b[39m100\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39m30027\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/lionelliu/Library/Mobile%20Documents/com~apple~CloudDocs/Uni/3rd%20Year/COMP30027%20Machine%20Learning/Proj%202%20-%28/German-Road-Sign-Classification/ml%20assign%202/COMP30027_ass_2.ipynb#X20sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m rf\u001b[39m.\u001b[39mfit(X, y)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/lionelliu/Library/Mobile%20Documents/com~apple~CloudDocs/Uni/3rd%20Year/COMP30027%20Machine%20Learning/Proj%202%20-%28/German-Road-Sign-Classification/ml%20assign%202/COMP30027_ass_2.ipynb#X20sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m y_predicted_rf \u001b[39m=\u001b[39m rf\u001b[39m.\u001b[39mpredict(X_test)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/ensemble/_forest.py:905\u001b[0m, in \u001b[0;36mForestClassifier.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    884\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict\u001b[39m(\u001b[39mself\u001b[39m, X):\n\u001b[1;32m    885\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    886\u001b[0m \u001b[39m    Predict class for X.\u001b[39;00m\n\u001b[1;32m    887\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    903\u001b[0m \u001b[39m        The predicted classes.\u001b[39;00m\n\u001b[1;32m    904\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 905\u001b[0m     proba \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredict_proba(X)\n\u001b[1;32m    907\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_outputs_ \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    908\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_\u001b[39m.\u001b[39mtake(np\u001b[39m.\u001b[39margmax(proba, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m), axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/ensemble/_forest.py:947\u001b[0m, in \u001b[0;36mForestClassifier.predict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    945\u001b[0m check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[1;32m    946\u001b[0m \u001b[39m# Check data\u001b[39;00m\n\u001b[0;32m--> 947\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_X_predict(X)\n\u001b[1;32m    949\u001b[0m \u001b[39m# Assign chunk of trees to jobs\u001b[39;00m\n\u001b[1;32m    950\u001b[0m n_jobs, _, _ \u001b[39m=\u001b[39m _partition_estimators(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_estimators, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_jobs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/ensemble/_forest.py:641\u001b[0m, in \u001b[0;36mBaseForest._validate_X_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    638\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    639\u001b[0m     force_all_finite \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m--> 641\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_data(\n\u001b[1;32m    642\u001b[0m     X,\n\u001b[1;32m    643\u001b[0m     dtype\u001b[39m=\u001b[39mDTYPE,\n\u001b[1;32m    644\u001b[0m     accept_sparse\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcsr\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    645\u001b[0m     reset\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    646\u001b[0m     force_all_finite\u001b[39m=\u001b[39mforce_all_finite,\n\u001b[1;32m    647\u001b[0m )\n\u001b[1;32m    648\u001b[0m \u001b[39mif\u001b[39;00m issparse(X) \u001b[39mand\u001b[39;00m (X\u001b[39m.\u001b[39mindices\u001b[39m.\u001b[39mdtype \u001b[39m!=\u001b[39m np\u001b[39m.\u001b[39mintc \u001b[39mor\u001b[39;00m X\u001b[39m.\u001b[39mindptr\u001b[39m.\u001b[39mdtype \u001b[39m!=\u001b[39m np\u001b[39m.\u001b[39mintc):\n\u001b[1;32m    649\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mNo support for np.int64 index based sparse matrices\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py:608\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    537\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_validate_data\u001b[39m(\n\u001b[1;32m    538\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    539\u001b[0m     X\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mno_validation\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    544\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_params,\n\u001b[1;32m    545\u001b[0m ):\n\u001b[1;32m    546\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Validate input data and set or check the `n_features_in_` attribute.\u001b[39;00m\n\u001b[1;32m    547\u001b[0m \n\u001b[1;32m    548\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    606\u001b[0m \u001b[39m        validated.\u001b[39;00m\n\u001b[1;32m    607\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 608\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_feature_names(X, reset\u001b[39m=\u001b[39mreset)\n\u001b[1;32m    610\u001b[0m     \u001b[39mif\u001b[39;00m y \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_tags()[\u001b[39m\"\u001b[39m\u001b[39mrequires_y\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[1;32m    611\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    612\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThis \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m estimator \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    613\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mrequires y to be passed, but the target y is None.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    614\u001b[0m         )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py:535\u001b[0m, in \u001b[0;36mBaseEstimator._check_feature_names\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    530\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m missing_names \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m unexpected_names:\n\u001b[1;32m    531\u001b[0m     message \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\n\u001b[1;32m    532\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFeature names must be in the same order as they were in fit.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    533\u001b[0m     )\n\u001b[0;32m--> 535\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(message)\n",
      "\u001b[0;31mValueError\u001b[0m: The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- mean_h\n- mean_s\n- mean_v\n- p10_b\n- p10_g\n- ...\nFeature names seen at fit time, yet now missing:\n- mean_h_x\n- mean_h_y\n- mean_s_x\n- mean_s_y\n- mean_v_x\n- ...\n"
     ]
    }
   ],
   "source": [
    "# lg = LogisticRegression(max_iter=11000)\n",
    "# lg.fit(X, y)\n",
    "# y_predicted_lg = lg.predict(X_test)\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=30027)\n",
    "rf.fit(X, y)\n",
    "y_predicted_rf = rf.predict(X_test)\n",
    "\n",
    "# stacker_lr.fit(X, y)\n",
    "# y_predicted_stacker_lr = stacker_lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# submission_lg = pd.DataFrame({\n",
    "#     'id': test_data['id'],\n",
    "#     'ClassId': y_predicted_lg\n",
    "# })\n",
    "# submission_lg.to_csv('submission_lg_with_custom_4.csv', index=False)\n",
    "\n",
    "submission_rf = pd.DataFrame({\n",
    "    'id': test_data['id'],\n",
    "    'ClassId': y_predicted_rf\n",
    "})\n",
    "submission_rf.to_csv('submission_rf_with_custom_4.csv', index=False)\n",
    "\n",
    "# submission_stacker_lr = pd.DataFrame({\n",
    "#     'id': test_data['id'],\n",
    "#     'ClassId': y_predicted_stacker_lr\n",
    "# })\n",
    "# submission_stacker_lr.to_csv('submission_stacker_1nn_dt_lr_rf.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
